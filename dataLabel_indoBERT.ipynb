{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('combined_data/combined_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load model dan tokenizer IndoBERT untuk klasifikasi sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"w11wo/indonesian-roberta-base-sentiment-classifier\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pindahkan model ke GPU jika tersedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fungsi untuk prediksi sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text, max_length=128):\n",
    "    # Encode teks\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=max_length)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Matikan gradient untuk inferensi\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    # Dapatkan prediksi terbesar\n",
    "    logits = outputs.logits\n",
    "    predicted_class = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Dapatkan probabilitas dengan softmax\n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    confidence = probs[0][predicted_class].item()\n",
    "    \n",
    "    # IndoBERT Sentiment memetakan label:\n",
    "    # 0: negative, 1: neutral, 2: positive\n",
    "    label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "    sentiment = label_map[predicted_class]\n",
    "    \n",
    "    return sentiment, confidence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Lakukan prediksi untuk seluruh dataset dalam batch untuk efisiensi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "sentiments = []\n",
    "confidences = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(df), batch_size)):\n",
    "    batch_texts = df['cleaned_text'].iloc[i:i+batch_size].tolist()\n",
    "    batch_results = [predict_sentiment(text) for text in batch_texts]\n",
    "    batch_sentiments, batch_confidences = zip(*batch_results)\n",
    "    \n",
    "    sentiments.extend(batch_sentiments)\n",
    "    confidences.extend(batch_confidences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Tambahkan kolom sentimen dan confidence ke datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = sentiments\n",
    "df['confidence'] = confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Simpan dataframe dengan label sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('combined_data/data_gabungan_twitter_tiktok_labeled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Tampilkan distribusi sentimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_counts = df['sentiment'].value_counts()\n",
    "print(\"Distribusi Sentimen:\")\n",
    "print(sentiment_counts)\n",
    "print(\"\\nPersentase Sentimen:\")\n",
    "print(sentiment_counts / len(df) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Mengekstrak subset untuk validasi manual (20% data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sample = df.groupby('sentiment', group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=0.2, random_state=42)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sample.to_csv('combined_data/validation_sample_20percent.csv', index=False)\n",
    "\n",
    "print(f\"\\nJumlah data untuk validasi manual: {len(validation_sample)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
